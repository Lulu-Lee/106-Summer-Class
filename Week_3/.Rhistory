knitr::opts_chunk$set(echo = TRUE)
summary(cars)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
5 + 3
5 + 3
4 - 2
attitude
ggplot(data=attitude, aes(x=rating, y=complaints)) + geom_point(aes(color=color))
library(ggplot2)
ggplot(data=attitude, aes(x=learning, y=raises)) + geom_bar(fill="lightgreen", color="black", stat="identity")
ggplot(data=attitude, aes(x=rating, y=complaints)) + geom_point(aes(color=color))
ggplot(data=attitude, aes(x=rating, y=complaints)) + geom_point(color="lightblue")
ggplot(data=attitude, aes(x=rating, y=complaints)) + geom_point(color="blue")
ggplot(data=attitude, aes(x=learning, y=raises)) + geom_bar(color="lightgreen", stat="identity")
ggplot(data=attitude, aes(x=learning, y=raises)) + geom_bar(fill="lightgreen", color="gray", stat="identity")
attitude
ggplot(data=attitude, aes(y=rating, x=advance, group="advance")) + geom_boxplot()
ggplot(data=attitude, aes(y=rating, x=1, group="advance")) + geom_boxplot()
ggplot(data=attitude, aes(y=rating, x=, group=)) + geom_violin()
ggplot(data=attitude, aes(y=privileges, x=learning) + geom_violin()
ggplot(data=attitude, aes(y=privileges, x=learning)) + geom_violin()
iris
ggplot(data=iris, aes(y=Sepal.Width,  x=Species)) + geom_violin()
ggplot(data=iris, aes(y=Sepal.Length, x=Petal.Length)) + geom_violin()
ggplot(data=iris, aes(y=Sepal.Length, x=Species)) + geom_violin(color="pink")
ggplot(data=iris, aes(y=Sepal.Length, x=Species)) + geom_violin(fill="pink", color="white")
ggplot(data=iris, aes(x=Sepal.Width, y=Petal.Width)) + geom_bar(fill="lightbrown", color="black")
ggplot(data=iris, aes(x=Sepal.Width)) + geom_bar(fill="lightbrown", color="black")
ggplot(data=iris, aes(x=Sepal.Width)) + geom_bar(fill="brown", color="black")
ggplot(data=attitude, aes(x=learning, y=raises)) + geom_bar(fill="lightgreen", color="gray", stat="identity")
ggplot(data=iris, aes(x=color)) + geom_bar(fill=Sepal.Width)
ggplot(data=iris, aes(x=Species)) + geom_bar(fill=clarity)
diamonds
iris
ggplot(data=iris, aes(x=Sepal.Length)) + geom_bar(fill=Species)
ggplot(data=iris, aes(x=Sepal.Length)) + geom_bar(fill=iris$Species)
ggplot(data=iris, aes(x=Sepal.Width, y=Petal.Width)) + geom_line(color="violet", size=1.5) + geom_point(color="golden", size=3.5)
ggplot(data=iris, aes(x=Sepal.Width, y=Petal.Width)) + geom_line(color="violet", size=1.5) + geom_point(color="yellow", size=3.5)
ggplot(data=iris, aes(x=Sepal.Width, y=Petal.Width)) + geom_line(color="violet", size=1.5) + geom_point(color="yellow", size=3)
ggplot(data=iris, aes(x=Sepal.Width, y=Petal.Width)) + geom_line(color="violet", size=2) + geom_point(color="yellow", size=3)
ggplot(data=iris, aes(x=Sepal.Width, y=Petal.Width)) + geom_path(color="violet", size=2) + geom_point(color="yellow", size=3)
ggplot(data=iris, aes(x=Sepal.Width, y=Petal.Width)) + geom_step(color="violet", size=2) + geom_point(color="yellow", size=3)
ggplot(data=iris, aes(x=Sepal.Width, y=Petal.Width)) + geom_path(color="violet", size=2) + geom_point(color="yellow", size=3)
?<gsub>
?gsub
?<gsub()>
?gsub()
getdoc <- function(url)
{
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
day <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
temp <- gsub( "  ", " 0", unlist(day) )
part <- strsplit( temp, split=" ", fixed=T )
daystamp <- part[[1]][4]
daystamp <- strsplit( daystamp, split=":", fixed=T )
date <- daystamp[[1]][1]
#print(date)
name <- paste0('./DATA/', date, ".txt")
write(doc, name, append = TRUE)
}
sapply(data, getdoc)
## Text Mining
from <- 2418 # 2018-07-18
to   <- 2430 # 2018-07-20
prefix = "https://www.ptt.cc/bbs/SENIORHIGH/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
## Text to Hours/Days
getdoc <- function(url)
{
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
day <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
temp <- gsub( "  ", " 0", unlist(day) )
part <- strsplit( temp, split=" ", fixed=T )
daystamp <- part[[1]][4]
daystamp <- strsplit( daystamp, split=":", fixed=T )
date <- daystamp[[1]][1]
#print(date)
name <- paste0('./DATA/', date, ".txt")
write(doc, name, append = TRUE)
}
sapply(data, getdoc)
from <- 2418 # 2018-07-18
to   <- 2430 # 2018-07-20
prefix = "https://www.ptt.cc/bbs/SENIORHIGH/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
library(bitops)
library(httr)
library(XML)
library(RCurl)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
from <- 2418 # 2018-07-18
to   <- 2430 # 2018-07-20
prefix = "https://www.ptt.cc/bbs/SENIORHIGH/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
getdoc <- function(url)
{
html <- htmlParse( getURL(url) )
doc  <- xpathSApply( html, "//div[@id='main-content']", xmlValue )
day <- xpathSApply( html, "//*[@id='main-content']/div[4]/span[2]", xmlValue )
temp <- gsub( "  ", " 0", unlist(day) )
part <- strsplit( temp, split=" ", fixed=T )
daystamp <- part[[1]][4]
daystamp <- strsplit( daystamp, split=":", fixed=T )
date <- daystamp[[1]][1]
#print(date)
name <- paste0('./DATA/', date, ".txt")
write(doc, name, append = TRUE)
}
sapply(data, getdoc)
install.packages("varhandle")
d.corpus <- Corpus( DirSource("./DATA") )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
mixseg = worker()
jieba_tokenizer = function(d)
{
unlist( segment(d[[1]], mixseg) )
}
seg = lapply(d.corpus, jieba_tokenizer)
count_token = function(d)
{
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
n = length(seg)
TDM = tokens[[1]]
colNames <- names(seg)
colNames <- gsub(".txt", "", colNames)
for( id in c(2:n) )
{
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', colNames[1:id])
}
TDM[is.na(TDM)] <- 0
kable(head(TDM))
library(bitops)
library(httr)
library(XML)
library(RCurl)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
library(ggplot2)
library(varhandle)
library(knitr)
mixseg = worker()
jieba_tokenizer = function(d)
{
unlist( segment(d[[1]], mixseg) )
}
seg = lapply(d.corpus, jieba_tokenizer)
count_token = function(d)
{
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
n = length(seg)
TDM = tokens[[1]]
colNames <- names(seg)
colNames <- gsub(".txt", "", colNames)
for( id in c(2:n) )
{
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', colNames[1:id])
}
TDM[is.na(TDM)] <- 0
kable(head(TDM))
kable(tail(TDM))
tf <- apply(as.matrix(TDM[,2:(n+1)]), 2, sum)
library(Matrix)
idfCal <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n+1)]), 1, idfCal)
doc.tfidf <- TDM
# for(x in 1:nrow(TDM))
# {
#   for(y in 2:ncol(TDM))
#   {
#     doc.tfidf[x,y] <- (doc.tfidf[x,y] / tf[y]) * idf[x]
#   }
# }
tempY = matrix(rep(c(as.matrix(tf)), each = length(idf)), nrow = length(idf))
tempX = matrix(rep(c(as.matrix(idf)), each = length(tf)), ncol = length(tf), byrow = TRUE)
doc.tfidf[,2:(n+1)] <- (doc.tfidf[,2:(n+1)] / tempY) * tempX
stopLine = rowSums(doc.tfidf[,2:(n+1)])
delID = which(stopLine == 0)
kable(head(doc.tfidf[delID,1]))
kable(tail(doc.tfidf[delID,1]))
TDM = TDM[-delID,]
doc.tfidf = doc.tfidf[-delID,]
library(bitops)
library(httr)
library(XML)
library(RCurl)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
library(ggplot2)
library(varhandle)
library(knitr)
library(Matrix)
TopWords = data.frame()
for( id in c(1:n) )
{
dayMax = order(doc.tfidf[,id+1], decreasing = TRUE)
showResult = t(as.data.frame(doc.tfidf[dayMax[1:5],1]))
TopWords = rbind(TopWords, showResult)
}
rownames(TopWords) = colnames(doc.tfidf)[2:(n+1)]
TopWords = droplevels(TopWords)
kable(TopWords)
TDM$d = as.character(TDM$d)
AllTop = as.data.frame( table(as.matrix(TopWords)) )
AllTop = AllTop[order(AllTop$Freq, decreasing = TRUE),]
kable(head(AllTop))
TopNo = 5
tempGraph = data.frame()
for( t in c(1:TopNo) )
{
word = matrix( rep(c(as.matrix(AllTop$Var1[t])), each = n), nrow = n )
temp = cbind( colnames(doc.tfidf)[2:(n+1)], t(TDM[which(TDM$d == AllTop$Var1[t]), 2:(n+1)]), word )
colnames(temp) = c("date", "freq", "words")
tempGraph = rbind(tempGraph, temp)
names(tempGraph) = c("date", "freq", "words")
}
tempGraph$freq = unfactor(tempGraph$freq)
ggplot(tempGraph, aes(hour, freq)) +
geom_point(aes(color = words, shape = words), size = 5) +
geom_line(aes(group = words, linetype = words))
TDM$d = as.character(TDM$d)
AllTop = as.data.frame( table(as.matrix(TopWords)) )
AllTop = AllTop[order(AllTop$Freq, decreasing = TRUE),]
kable(head(AllTop))
TopNo = 5
tempGraph = data.frame()
for( t in c(1:TopNo) )
{
word = matrix( rep(c(as.matrix(AllTop$Var1[t])), each = n), nrow = n )
temp = cbind( colnames(doc.tfidf)[2:(n+1)], t(TDM[which(TDM$d == AllTop$Var1[t]), 2:(n+1)]), word )
colnames(temp) = c("date", "freq", "words")
tempGraph = rbind(tempGraph, temp)
names(tempGraph) = c("date", "freq", "words")
}
tempGraph$freq = unfactor(tempGraph$freq)
ggplot(tempGraph, aes(date, freq)) +
geom_point(aes(color = words, shape = words), size = 5) +
geom_line(aes(group = words, linetype = words))
kable(tail(AllTop))
filenames = as.array(paste0("./DATA/",colnames(doc.tfidf)[2:(n+1)],".txt"))
sizeResult = apply(filenames, 1, file.size) / 1024
showSize = data.frame(colnames(doc.tfidf)[2:(n+1)], sizeResult)
names(showSize) = c("date", "size_KB")
ggplot(showSize, aes(x = date, y = size_KB)) + geom_bar(stat="identity")
library(bitops)
library(httr)
library(XML)
library(RCurl)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
library(Matrix)
library(ggplot2)
library(varhandle)
library(knitr)
from <- 2418 # 2018-07-18
to   <- 2430 # 2018-07-20
prefix = "https://www.ptt.cc/bbs/SENIORHIGH/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
from <- 2418 # 2018-07-18
to   <- 2430 # 2018-07-20
prefix = "https://www.ptt.cc/bbs/SENIORHIGH/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
from <- 2418 # 2018-07-18
to   <- 2430 # 2018-07-20
prefix = "https://www.ptt.cc/bbs/SENIORHIGH/index"
data <- list()
for( id in c(from:to) )
{
url  <- paste0( prefix, as.character(id), ".html" )
html <- htmlParse( GET(url) )
url.list <- xpathSApply( html, "//div[@class='title']/a[@href]", xmlAttrs )
data <- rbind( data, as.matrix(paste('https://www.ptt.cc', url.list, sep='')) )
}
data <- unlist(data)
head(data)
d.corpus <- Corpus( DirSource("./DATA") )
d.corpus <- tm_map(d.corpus, removePunctuation)
d.corpus <- tm_map(d.corpus, removeNumbers)
d.corpus <- tm_map(d.corpus, function(word) {
gsub("[A-Za-z0-9]", "", word)
})
mixseg = worker()
jieba_tokenizer = function(d)
{
unlist( segment(d[[1]], mixseg) )
}
seg = lapply(d.corpus, jieba_tokenizer)
count_token = function(d)
{
as.data.frame(table(d))
}
tokens = lapply(seg, count_token)
n = length(seg)
TDM = tokens[[1]]
colNames <- names(seg)
colNames <- gsub(".txt", "", colNames)
for( id in c(2:n) )
{
TDM = merge(TDM, tokens[[id]], by="d", all = TRUE)
names(TDM) = c('d', colNames[1:id])
}
TDM[is.na(TDM)] <- 0
kable(head(TDM))
kable(tail(TDM))
tf <- apply(as.matrix(TDM[,2:(n+1)]), 2, sum)
idfCal <- function(word_doc)
{
log2( n / nnzero(word_doc) )
}
idf <- apply(as.matrix(TDM[,2:(n+1)]), 1, idfCal)
doc.tfidf <- TDM
# for(x in 1:nrow(TDM))
# {
#   for(y in 2:ncol(TDM))
#   {
#     doc.tfidf[x,y] <- (doc.tfidf[x,y] / tf[y]) * idf[x]
#   }
# }
tempY = matrix(rep(c(as.matrix(tf)), each = length(idf)), nrow = length(idf))
tempX = matrix(rep(c(as.matrix(idf)), each = length(tf)), ncol = length(tf), byrow = TRUE)
doc.tfidf[,2:(n+1)] <- (doc.tfidf[,2:(n+1)] / tempY) * tempX
stopLine = rowSums(doc.tfidf[,2:(n+1)])
delID = which(stopLine == 0)
kable(head(doc.tfidf[delID,1]))
kable(tail(doc.tfidf[delID,1]))
TDM = TDM[-delID,]
doc.tfidf = doc.tfidf[-delID,]
filenames = as.array(paste0("./DATA/",colnames(doc.tfidf)[2:(n+1)],".txt"))
sizeResult = apply(filenames, 1, file.size) / 1024
showSize = data.frame(colnames(doc.tfidf)[2:(n+1)], sizeResult)
names(showSize) = c("date", "size_KB")
ggplot(showSize, aes(x = date, y = size_KB)) + geom_bar(stat="identity")
filenames = as.array(paste0("./DATA/",colnames(doc.tfidf)[2:(n+1)],".txt"))
sizeResult = apply(filenames, 1, file.size) / 1024
showSize = data.frame(colnames(doc.tfidf)[2:(n+1)], sizeResult)
names(showSize) = c("date", "size_KB")
ggplot(showSize, aes(x = date, y = size_KB)) + geom_bar(fill="pink", color="white", stat="identity")
TDM$d = as.character(TDM$d)
AllTop = as.data.frame( table(as.matrix(TopWords)) )
AllTop = AllTop[order(AllTop$Freq, decreasing = TRUE),]
kable(head(AllTop))
TopNo = 5
tempGraph = data.frame()
for( t in c(1:TopNo) )
{
word = matrix( rep(c(as.matrix(AllTop$Var1[t])), each = n), nrow = n )
temp = cbind( colnames(doc.tfidf)[2:(n+1)], t(TDM[which(TDM$d == AllTop$Var1[t]), 2:(n+1)]), word )
colnames(temp) = c("date", "freq", "words")
tempGraph = rbind(tempGraph, temp)
names(tempGraph) = c("date", "freq", "words")
}
setwd("C:/Users/huihu/Desktop/CS+X/106-Summer-Class/Week_3")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
docs.pca <- prcomp(docs.tfidf, scale = T)
docs.corpus <- Corpus(DirSource("./DATA"))
docs.seg <- tm_map(docs.corpus, segmentCN)
docs.tdm <- TermDocumentMatrix(docs.seg)
docs.tf <- apply(as.matrix(docs.tdm), 2, function(word) { word/sum(word) })
idf <- function(doc) {
return ( log2( length(doc)+1 / nnzero(doc)) )
}
docs.idf <- apply(as.matrix(docs.tdm), 1, idf)
docs.tfidf <- docs.tf * docs.idf
docs.pca <- prcomp(docs.tfidf, scale = T)
fviz_eig(docs.pca)
library(bitops)
library(httr)
library(XML)
library(RCurl)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
library(Matrix)
library(ggplot2)
library(varhandle)
library(knitr)
library(factoextra)
install.packages("factoextra")
library(bitops)
library(httr)
library(XML)
library(RCurl)
library(tm)
library(NLP)
library(tmcn)
library(jiebaRD)
library(jiebaR)
library(Matrix)
library(ggplot2)
library(varhandle)
library(knitr)
library(factoextra)
docs.pca <- prcomp(docs.tfidf, scale = T)
fviz_eig(docs.pca)
fviz_pca_ind(docs.pca, geom.ind = c("point"), col.ind = "cos2")
fviz_pca_var(docs.pca, col.var = "contrib")
fviz_pca_var(docs.pca, col.var = "contrib")
docs.eig <- get_eig(docs.pca)
docs.var <- get_pca_var(docs.pca)
docs.ind <- get_pca_ind(docs.pca)
